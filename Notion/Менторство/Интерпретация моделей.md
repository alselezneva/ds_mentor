---
Категория:
  - DS-материал
---
AI Explainability beyond the Surface: Uncommon Techniques, Categories and Top 60 Python Libraries 📚

In this post together we delve into Advanced XAI, XAI characteristics, Categories and Python libraries.

——————

Characteristics of XAI:

> ҉ Transparency  
> ҉ Justification  
> ҉ Informativeness  
> ҉ Reliability  

——————

Categories of XAI:

೫ Feature attribution:  
Determine Feature Importance  

೫ Instance based:  
Determine Subset of features that guarantee a prediction  

೫ Graph Convolution based:  
Interpret Model using subgraphs  

೫ Self explaining:  
Develop Model that are explainable by Design  

೫ Uncertainty Estimation:  
Quantify the reliability of a prediction  

——————

Advanced XAI methods:

Diving into some examples in the categories and also other types:

🅞 Counterfactual: alternative scenarios that could have led to a different AI decision.

🅞 Human-Readable Rule Extraction: extract human-readable rules from complex models

🅞 Attention Mechanisms: highlight the important features or regions in input data that influenced an AI decision.

🅞 NLP techniques: can generate explanations in human-readable language to provide intuitive insights

🅞 Bayesian Networks: enable understanding of causal relationships within AI models.

🅞 Model Confidence: conveying model confidence and uncertainty in predictions.

🅞 Adversarial Explanation: testing AI models with intentionally modified inputs to reveal vulnerabilities or biases.

🅞 Transfer Learning: widely used for improving AI performance, can also enhance explainability.

🅞 Interactive Explanations: allow users to actively engage with AI systems and explore decision pathways.

🅞 Integrating Human Feedback Loops: by incorporating iterative feedback loops from human users.

——————

I found these 60 Python Libraries for AI Explainability and Model Interpretability:

📚 SHAP  
📚 LIME  
📚 ELI5  
📚 Alibi  
📚 interpret  
📚 Dalex  
📚 AI Explainability 360  
📚 Captum  
📚 Skater  
📚 Fairlearn  
📚 Fairness Indicators  
📚 Yellowbrick  
📚 PyCEbox  
📚 Anchor  
📚 SHAPash  
📚 DiCE  
📚 Aequitas  
📚 CleverHans  
📚 PrivacyRaven  
📚 interpretML  
📚 PDPbox  
📚 Fairness  
📚 FAT Forensics  
📚 What-If Tool  
📚 certifai  
📚 Explanatory Model Analysis  
📚 XAI  
📚 Fairness Comparison  
📚 Ai explainability  
📚 BlackBoxAuditing  
📚 Deap  
📚 Facets  
📚 TCAV  
📚 Grad-CAM  
📚 AIX360  
📚 fairkit-learn  
📚 Adversarial Robustness Toolbox (ART)  
📚  
[ExplainX.ai](http://explainx.ai/)  
📚 Treeinterpreter  
📚  
[H2O.ai](http://h2o.ai/) Explainability  
📚 TensorFlow Explain  
📚 Concept Activation Vectors  
📚 Holoclean  
📚 Saabas  
📚 RelEx  
📚 iNNvestigate  
📚 Profweight  
📚 XDeep  
📚 DeepLIFT  
📚 L2X  
📚 Fiddler AI  
📚 TrustyAI  
📚 RAI  
📚 LimeTabular  
📚 Gamut  
📚 cxplain  
📚 AnchorTabular  
📚 H2O-3 Explainability  
📚 Alibi Detect  
📚 WeightWatcher