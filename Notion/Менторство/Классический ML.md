---
Категория:
  - MOCK-интервью
---
[https://youtu.be/Us_TKT8ZL2E](https://youtu.be/Us_TKT8ZL2E)

[https://telegra.ph/Sobesedovanie-na-poziciyu-Data-Scientist-46-tipichnyh-voprosov-CHast-1-07-06](https://telegra.ph/Sobesedovanie-na-poziciyu-Data-Scientist-46-tipichnyh-voprosov-CHast-1-07-06)

[https://telegra.ph/Sobesedovanie-na-poziciyu-Data-Scientist-46-tipichnyh-voprosov-CHast-2-07-06](https://telegra.ph/Sobesedovanie-na-poziciyu-Data-Scientist-46-tipichnyh-voprosov-CHast-2-07-06)

1. Линейные модели
2. Опишите задачу машинного обучения. Дайте определение объекту, целевой  
    переменной, признакам, модели, функционалу ошибки.  
    
3. Чем отличается функция потерь от функционала ошибки?
4. Какие функции потерь используются при решении задачи регрессии?
5. Запишите формулу для линейной модели регрессии.
6. Чем отличаются функционалы MSE и MAE? В каких случаях лучше использовать  
    MSE, а в каких MAE?  
    
7. Чем отличается MAE от MAPE? Что более понятно заказчику продукта?
8. Что такое коэффициент детерминации? Как интерпретировать его значения?
9. Чем log-cosh лучше функции потерь Хубера? Опишите обе функции потерь.
10. Что такое градиент? Какое его свойство используется при минимизации функций?
11. Что такое градиентный спуск? Опишите процесс алгоритма.
12. Почему не всегда можно использовать полный градиентный спуск? Какие способы  
    оценивания градиента вы знаете? Почему в стохастическом градиентном спуске важно  
    менять длину шага по мере итераций? Какие стратегии изменения шага вы знаете?  
    
13. Что такое переобучение? Как можно отследить переобучение модели?
14. Что такое кросс-валидация? На что влияет количество блоков в кросс-валидации?
15. Как построить итоговую модель после того, как по кросс-валидации подобраны  
    оптимальные гиперпараметры?  
    
16. Что такое регуляризация? Для чего используется?
17. Опишите, как работают L1- и L2-регуляризаторы.
18. Почему L1-регуляризация отбирает признаки?
19. Почему плохо накладывать регуляризацию на свободный коэффициент?
20. Где используется метод максимального праводоподобия?
21. Расскажите про метрики, которые штрафуют за перепрогноз сильнее, чем за  
    недопрогноз и наоборот(pinball loss)  
    
22. Расскажите про виды скейлинга. Зачем они нужны?
23. Как записываются аналитическое решения? Какие у них проблемы?
24. Классификация
25. Запишите формулу для линейной модели классификации. Что такое отступ?
26. Как обучаются линейные классификаторы и для чего нужны верхние оценки  
    пороговой функции потерь?  
    
27. Что такое точность, полнота и F-мера? Почему F-мера лучше арифметического  
    среднего и минимума?  
    
28. Для чего нужен порог в линейном классификаторе? Из каких соображений он может  
    выбираться?  
    
29. Что такое AUC-ROC? Опишите алгоритм построения ROC-кривой.
30. Что такое AUC-PRC? Опишите алгоритм построения PR-кривой.
31. Что означает “модель оценивает вероятность положительного класса”? Как можно  
    внедрить это требование в процедуру обучения модели?  
    8.Запишитефункционаллогистическойрегрессии.Каконсвязансметодоммаксимума  
    правдоподобия?  
    
32. Когда используется accuracy?
33. Как бороться с дисбалансом классов?  
    1  
    Машинное обучение  
    [postypashki.ru](http://postypashki.ru/) [vk.com/postypashki](http://vk.com/postypashki)
34. Многоклассофая классификация
35. Как измеряется качество в задаче многоклассовой классификации?
36. Расскажите микро и макро-усреднение?
37. Что такое mean-target encoding?
38. Может ли mean-target encoding может привести к переобучению? Как можно этого  
    избежать?  
    
39. Как можно отбирать признаки для линейной модели?
40. Что такое решающее дерево?
41. Опишите жадный алгоритм обучения решающего дерева.
42. Почему с помощью бинарного решающего дерева можно достичь нулевой ошибки  
    на обучающей выборке без повторяющихся объектов?  
    
43. Что такое критерий хаотичности? Как он используется для выбора предиката во  
    внутренней вершине решающего дерева?  
    
44. В чем отличия энтропийного критерия и критерия Джини?
45. Как связаны линейные модели и решающие деревья?
46. Как посчитать хаотичность вершины в задачи классификации? А в задачи  
    регрессии?  
    
47. В чем заключается метод опорных векторов?
48. В чем заключается метод k-ближайших соседей?
49. Нужно ли заниматься предобработкой данных в случае дерева?
50. Как деревья работают с Nan?
51. Как деревья работают с категориальными значениями?
52. Как сделать многоклассовую классификацию через логрег?
53. Леса
54. Приведите пример семейства алгоритмов с низким смещением и большим разбросом.
55. Приведите пример семейства алгоритмов с большим смещением и низким разбросом.
56. Что такое бэггинг? Как его смещение и разброс связаны со смещением и разбросом  
    базовых моделей?  
    
57. Что такое случайный лес? Чем он отличается от бэггинга над решающими  
    деревьями?  
    
58. Перечислите основные плюсы решающего леса.
59. Назовите недостатки случайного леса.
60. Как работает алгоритм градиентного бустинга.
61. Как обычно выглядят базовые модели в бустинге. Опишите почему?
62. Что такое сдвиги в градиентном бустинге, зачем они нужны?
63. Как обучается очередной базовый алгоритм в градиентном бустинге
64. Расскажите про виды бустинга(catboost, lgbm, xgb), их особенности и различия
65. Почему дерево строится по MSE (идея, что связано с косинусным расстоянием)?
66. Как работает oob?
67. Как работает feature importance?
68. Кластеризация
69. Опишите задачу кластеризации. Приведите примеры.
70. Метрики качества кластеризации.
71. Расскажите про алгоритмы кластеризации, которые вы знаете (например, k-means,  
    dbscan